# app.py
import streamlit as st
from embedding_query_and_searches_ngocson import QdrantSearcher
from groq import Groq
from config import get_settings

# ---------------------------------------------------------------------------
# ‚öôÔ∏è Load c·∫•u h√¨nh v√† kh·ªüi t·∫°o client
# ---------------------------------------------------------------------------
settings = get_settings()  # Load c√°c thi·∫øt l·∫≠p t·ª´ config.py

# Kh·ªüi t·∫°o Groq LLM client
groq_client = Groq(api_key=settings.GROQ_API_KEY)

# Kh·ªüi t·∫°o Qdrant searcher ƒë·ªÉ th·ª±c hi·ªán c√°c lo·∫°i search
searcher = QdrantSearcher()


# ---------------------------------------------------------------------------
# üñ•Ô∏è Giao di·ªán ng∆∞·ªùi d√πng Streamlit
# ---------------------------------------------------------------------------
st.set_page_config(page_title="Hybrid Search + LLM", layout="wide")

st.title("ü§ñ Hybrid Search + Groq LLM Assistant")
st.write("Nh·∫≠p c√¢u truy v·∫•n ƒë·ªÉ t√¨m ki·∫øm d·ªØ li·ªáu v√† sinh c√¢u tr·∫£ l·ªùi th√¥ng minh.")

# Input query t·ª´ ng∆∞·ªùi d√πng
query = st.text_area(
    "Nh·∫≠p truy v·∫•n:", placeholder="V√≠ d·ª•: Transformer l√† g√¨?", height=100
)

# L·ª±a ch·ªçn chi·∫øn l∆∞·ª£c t√¨m ki·∫øm
search_mode = st.radio(
    "Ch·ªçn chi·∫øn l∆∞·ª£c t√¨m ki·∫øm:",
    ["Hybrid Search", "Semantic Search"],
    horizontal=True,
)

# Slider cho top_k v√† alpha
col1, col2 = st.columns(2)

with col1:
    top_k = st.slider("S·ªë k·∫øt qu·∫£ hi·ªÉn th·ªã:", 1, 10, 6)

with col2:
    # üîπ Alpha ch·ªâ kh·∫£ d·ª•ng khi ch·ªçn Hybrid Search
    if search_mode == "Hybrid Search":
        alpha = st.slider(
            "H·ªá s·ªë alpha (0 = keyword, 1 = semantic):", 0.0, 1.0, 0.6, step=0.1
        )
    else:
        # Disabled slider, ch·ªâ hi·ªÉn th·ªã gi√° tr·ªã m·∫∑c ƒë·ªãnh
        alpha = st.slider(
            "H·ªá s·ªë alpha (ch·ªâ √°p d·ª•ng cho Hybrid Search):",
            0.0,
            1.0,
            0.6,
            step=0.1,
            disabled=True,
        )


# ---------------------------------------------------------------------------
# üîç X·ª≠ l√Ω truy v·∫•n khi ng∆∞·ªùi d√πng nh·∫•n n√∫t "H·ªèi AI"
# ---------------------------------------------------------------------------
if st.button("üîç H·ªèi AI"):
    if not query.strip():
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung truy v·∫•n.")
    else:
        with st.spinner("üîé ƒêang t√¨m ki·∫øm d·ªØ li·ªáu..."):
            try:
                # Ch·ªçn lo·∫°i search ph√π h·ª£p
                if search_mode == "Hybrid Search":
                    results = searcher.hybrid_search(query, top_k=top_k, alpha=alpha)
                elif search_mode == "Semantic Search":
                    results = searcher.semantic_search(query, top_k=top_k)
            except Exception as e:
                st.error(f"L·ªói khi g·ªçi h√†m search: {e}")
                results = []

        # -------------------------------------------------------------------
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm t·ª´ Qdrant
        # -------------------------------------------------------------------
        if results:
            with st.expander(
                f"üîç Hi·ªÉn th·ªã {len(results)} k·∫øt qu·∫£ t√¨m ki·∫øm", expanded=False
            ):
                st.success(f"ƒê√£ t√¨m th·∫•y {len(results)} k·∫øt qu·∫£ t·ª´ Qdrant:")
                for i, res in enumerate(results, start=1):
                    st.markdown(f"**{i}. {res.get('text', '')}**")
                    st.caption(
                        f"Score: {res.get('score', 0):.4f} | Source: {res.get('source', '')}"
                    )

            # -------------------------------------------------------------------
            # Chu·∫©n b·ªã b·ªëi c·∫£nh (context) cho LLM
            # -------------------------------------------------------------------
            context = "\n".join([r.get("text", "") for r in results])

            # T·∫°o prompt chi ti·∫øt cho AI, ƒë·∫£m b·∫£o ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ Qdrant
            prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI tr·∫£ l·ªùi c√¢u h·ªèi.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc k·ªπ b·ªëi c·∫£nh ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y v√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch ch√≠nh x√°c v√† ng·∫Øn g·ªçn.

**QUY T·∫ÆC B·∫ÆT BU·ªòC:**
1. CH·ªà ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng th√¥ng tin t·ª´ m·ª•c [B·ªëi c·∫£nh t·ª´ t√†i li·ªáu] ƒë·ªÉ h√¨nh th√†nh c√¢u tr·∫£ l·ªùi.
2. KH√îNG ƒë∆∞·ª£c s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i ho·∫∑c th√¥ng tin c√≥ s·∫µn trong m√¥ h√¨nh c·ªßa b·∫°n.
3. N·∫øu c√¢u tr·∫£ l·ªùi kh√¥ng c√≥ trong b·ªëi c·∫£nh, h√£y tr·∫£ l·ªùi th·∫≥ng th·∫Øn l√†: "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y trong t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p."

[B·ªëi c·∫£nh t·ª´ t√†i li·ªáu]:
{context}

[C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng]:
{query}
[C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n]:
"""

            # -------------------------------------------------------------------
            # G·ªçi Groq API ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi
            # -------------------------------------------------------------------
            with st.spinner("üí≠ ƒêang sinh c√¢u tr·∫£ l·ªùi t·ª´ Groq..."):
                try:
                    response = groq_client.chat.completions.create(
                        model=settings.GROQ_MODEL_NAME,
                        messages=[
                            {
                                "role": "system",
                                "content": "B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán v√† h·ªØu √≠ch.",
                            },
                            {"role": "user", "content": prompt},
                        ],
                        temperature=0.5,
                    )
                    answer = response.choices[0].message.content
                    st.markdown("### üí¨ Ph·∫£n h·ªìi t·ª´ AI:")
                    st.write(answer)
                except Exception as e:
                    st.error(f"L·ªói khi g·ªçi Groq API: {e}")

        else:
            st.warning("‚ùå Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o trong Qdrant.")
